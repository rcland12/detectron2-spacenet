{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b819c4e-408e-4d9c-8e31-02f8ede1cf3e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec3c535-9201-48a2-a63c-88d0b6be6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "import detectron2\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from utils.functions import grab_certain_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8be4614c-0c28-443c-88ca-eabdf467d50d",
   "metadata": {},
   "source": [
    "# Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62089579-5c9a-402c-b786-d835a322c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_dicts(img_dir):\n",
    "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, annots in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "        \n",
    "        filename = os.path.join(img_dir, annots[\"filename\"])\n",
    "        height, width = cv.imread(filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "      \n",
    "        annotations = annots[\"regions\"]\n",
    "        objs = []\n",
    "        for _, anno in annotations.items():\n",
    "            assert not anno[\"region_attributes\"]\n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            obj = {\"bbox\": [np.min(px),\n",
    "                            np.min(py),\n",
    "                            np.max(px),\n",
    "                            np.max(py)\n",
    "                           ],\n",
    "                   \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                   \"segmentation\": [poly],\n",
    "                   \"category_id\": anno[\"category\"]\n",
    "                  }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7b3b1-e5d1-4e85-98ca-e1c4841a6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"building\"]\n",
    "colors = [(249, 180, 45)]\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(d, lambda d=d: get_dataset_dicts(os.path.join(\"Spacenet\", d)))\n",
    "    MetadataCatalog.get(d).thing_classes = classes\n",
    "    MetadataCatalog.get(d).thing_colors = colors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fb8a127-1534-4af8-97b7-cb0d6a276d9d",
   "metadata": {},
   "source": [
    "# Visualize Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cfd1b-ee51-4134-ace5-d11911110e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get(\"train\")\n",
    "dataset_dicts = get_dataset_dicts(\"Spacenet/train\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1, instance_mode=ColorMode.IMAGE)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    print(d[\"file_name\"])\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85064121-d255-4c00-9cf8-a8789a916f85",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4a9e9-de05-4c07-9c74-a3b586ae301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n",
    "cfg.OUTPUT_DIR = \"Spacenet/output\"\n",
    "\n",
    "# Save your configurations for multi-GPU use\n",
    "with open(\"Spacenet/SpacenetD2cfg.yaml\", \"w\") as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cd4c1b2-ecbf-4753-8711-e491dc588508",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b5501-600f-4f3b-acb3-967387e7d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbd374d5-9363-4f11-bd91-3330eb4df566",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee6f4d2",
   "metadata": {},
   "source": [
    "If you are just inferencing, make sure you define the cfg above. Run the configuration block above and the block below afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "metadata = MetadataCatalog.get(\"train\")\n",
    "\n",
    "# Overwriting configs for inference\n",
    "with open(\"Spacenet/SpacenetD2cfg.yaml\", \"w\") as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d3c0fa6-64d9-444a-a755-e8bfdb73811f",
   "metadata": {},
   "source": [
    "## Built-in Image Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7aee2-d77b-4338-85ad-ef736a891472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference/demo.py \\\n",
    "--config-file Spacenet/SpacenetD2cfg.yaml \\\n",
    "--input Spacenet/test/*.png \\\n",
    "--output Spacenet/predicitions \\\n",
    "--confidence-threshold 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c3b756-99f9-431c-a1d1-efbf0c464143",
   "metadata": {},
   "source": [
    "## Built-in Video Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c74e-93d6-47bc-b24a-7fd13539e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference/demo.py \\\n",
    "--config-file Spacenet/SpacenetD2cfg.yaml \\\n",
    "--video-input example.mp4 \\\n",
    "--output example_output.mp4 \\\n",
    "--confidence-threshold 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f53f179b-a8ff-44aa-bcdb-27ac32a2494e",
   "metadata": {},
   "source": [
    "## Homemade Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4466337-b182-43cb-861a-94065e2a1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pred_detectron2(files, file_path, dest, metadata, predictor):\n",
    "    for item in tqdm(files, desc = \"Inferencing on testing images\", ncols = 150, bar_format=\"{l_bar}{bar:10}{r_bar}\"):\n",
    "        destination = os.path.join(dest, item)\n",
    "        in_frame = cv.imread(os.path.join(file_path, item))\n",
    "        outputs = predictor(in_frame[:, :, ::-1])\n",
    "        v = Visualizer(in_frame[:, :, ::-1], metadata=metadata, instance_mode = ColorMode.SEGMENTATION)\n",
    "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        out_frame = v.get_image()[:, :, ::-1]\n",
    "        cv.imwrite(destination, out_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
